{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8d04460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['joy', 'fear', 'anger', 'sadness', 'love', 'surprise']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'maxlen' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21420/3919276027.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[1;31m#Create the model by identifying different layers and setting their parameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m model = tf.keras.models.Sequential([\n\u001b[1;32m--> 107\u001b[1;33m         \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmaxlen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    108\u001b[0m         \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBidirectional\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGRU\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m         \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBidirectional\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGRU\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'maxlen' is not defined"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import random\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import fbeta_score\n",
    "\n",
    "#Create functions for the accuracy and loss graphs\n",
    "def show_history(h):\n",
    "    epochs_trained = len(h.history['loss'])\n",
    "    plt.figure(figsize=(16, 6))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(range(0, epochs_trained), h.history.get('accuracy'), label='Training')\n",
    "    plt.plot(range(0, epochs_trained), h.history.get('val_accuracy'), label='Validation')\n",
    "    plt.ylim([0., 1.])\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(range(0, epochs_trained), h.history.get('loss'), label='Training')\n",
    "    plt.plot(range(0, epochs_trained), h.history.get('val_loss'), label='Validation')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "#Create functions for the confusion matrix    \n",
    "def show_confusion_matrix(y_true, y_pred, classes):\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    \n",
    "    cm = confusion_matrix(y_true, y_pred, normalize='true')\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    sp = plt.subplot(1, 1, 1)\n",
    "    ctx = sp.matshow(cm)\n",
    "    plt.xticks(list(range(0, 6)), labels=classes)\n",
    "    plt.yticks(list(range(0, 6)), labels=classes)\n",
    "    plt.colorbar(ctx)\n",
    "    plt.show()\n",
    "\n",
    "#Load the train, validation and testing datasets   \n",
    "train = pd.read_csv(\"G:\\My Drive\\AnjanaValsalan_ECNG 3020\\Implementation Files\\Datasets\\ECNG3020_Final_Dataset\\ECNG3020_Train_Dataset.csv\")\n",
    "test = pd.read_csv(\"G:\\My Drive\\AnjanaValsalan_ECNG 3020\\Implementation Files\\Datasets\\ECNG3020_Final_Dataset\\ECNG3020_Test_Dataset.csv\")\n",
    "val = pd.read_csv(\"G:\\My Drive\\AnjanaValsalan_ECNG 3020\\Implementation Files\\Datasets\\ECNG3020_Final_Dataset\\ECNG3020_Val_Dataset.csv\")\n",
    "\n",
    "#Create function that separate text and labels in the dataset into different variables\n",
    "def get_text(data):\n",
    "    text = data['text']\n",
    "    labels = data['label']\n",
    "    labels = labels.replace([\"0\",\"1\",\"2\",\"3\",\"4\",\"5\"],['sadness','joy','love','anger','fear','surprise'])\n",
    "    return text, labels\n",
    "\n",
    "#Apply get_text() function to the train set\n",
    "text, labels = get_text(train)\n",
    "\n",
    "#Use the TensorFlow Keras Tokenizer on the text values from the train set\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "tokenizer = Tokenizer(num_words=10000, oov_token='<UNK>')\n",
    "tokenizer.fit_on_texts(text)\n",
    "\n",
    "#Plot a histogram for the lengths of each text value in the train set to determine a value for max_length\n",
    "lengths = [len(t.split(' ')) for t in text]\n",
    "plt.hist(lengths, bins = len(set(lengths)))\n",
    "plt.show\n",
    "maxlength = 50\n",
    "\n",
    "#import the pad_sequences function for padding and truncting text values in the train set\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "#Create a function for padding and truncating the text values in the dataset to be maxlength\n",
    "def get_sequences(tokenizer, text):\n",
    "  sequences = tokenizer.texts_to_sequences(text)\n",
    "  padded = pad_sequences(sequences, truncating='post' , padding='post', maxlen = maxlength)\n",
    "  return padded\n",
    "\n",
    "#Apply the get_sequences() function to the train set\n",
    "padded_train_seq = get_sequences(tokenizer, text)\n",
    "\n",
    "#Set the classes as the six emotions \n",
    "classes = ['joy', 'fear', 'anger', 'sadness', 'love', 'surprise']\n",
    "print(classes)\n",
    "\n",
    "#Plot a histogram to show the data distribution for each label\n",
    "plt.hist(labels, bins=11)\n",
    "plt.show()\n",
    "\n",
    "#Allow classes to be converted to indices and vice versa\n",
    "class_to_index = dict((c,i) for i, c in enumerate(classes))\n",
    "index_to_class = dict((v, k) for k, v in class_to_index.items())\n",
    "\n",
    "#Convert the label names to integer IDs using the class to index \n",
    "names_to_ids = lambda labels: np.array([class_to_index.get(x) for x in labels])\n",
    "\n",
    "#Convert the labels in the train set to integer IDs\n",
    "train_labels = names_to_ids(labels)\n",
    "\n",
    "#Set the L2 regularizer to 0.02\n",
    "l2 = tf.keras.regularizers.L2(\n",
    "    l2=0.02)\n",
    "\n",
    "#Create the model by identifying different layers and setting their parameters \n",
    "model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Embedding(10000, 16, input_length=maxlength),\n",
    "        tf.keras.layers.Bidirectional(tf.keras.layers.GRU(20, return_sequences=True)),\n",
    "        tf.keras.layers.Bidirectional(tf.keras.layers.GRU(20)),\n",
    "        tf.keras.layers.Dropout(.5, input_shape=(2,)),\n",
    "        tf.keras.layers.Dense(6, activation='softmax',kernel_regularizer = l2)\n",
    "])\n",
    "\n",
    "#Set optimizer to Adam with a learning rate of 0.01\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "     learning_rate=0.01)\n",
    "\n",
    "#Compile the model with a sparse_categorical crossentropy loss, adam optimizer\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer= optimizer,\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "#Output a model summary to verify the architecture\n",
    "model.summary()\n",
    "\n",
    "#Apply the get_text and get_sequences functions to the validation sets\n",
    "val_text, val_labels = get_text(val)\n",
    "val_seq = get_sequences(tokenizer, val_text)\n",
    "val_labels = names_to_ids(val_labels)\n",
    "\n",
    "#Train the model for a specified number of epochs and validate with the validation set\n",
    "from datetime import datetime\n",
    "\n",
    "h = model.fit(\n",
    "    padded_train_seq, train_labels,\n",
    "    validation_data=(val_seq, val_labels),\n",
    "    epochs=20,\n",
    "    callbacks=[\n",
    "               tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=2),\n",
    "        tf.keras.callbacks.ModelCheckpoint(filepath = \"C:/Users/valsa/OneDrive - The University of the West Indies, St. Augustine/Final Year/ECNG 3020/Iris/Python Scripts/Alternative Model/Best Model\".format(datetime.now().strftime(\"%d%m%Y_%H_%M_%S\")),save_best_only=True)\n",
    "    ]\n",
    ")\n",
    "\n",
    "#Output the accuracy and loss graphs to compare performance on train and validation sets\n",
    "show_history(h)\n",
    "\n",
    "#Apply get_text and get_sequences functions to the test set\n",
    "test_text, test_labels = get_text(test)\n",
    "test_seq = get_sequences(tokenizer, test_text)\n",
    "test_labels = names_to_ids(test_labels)\n",
    "\n",
    "#Evaluate the model on the test set\n",
    "_=model.evaluate(test_seq, test_labels)\n",
    "\n",
    "#Use the model to predict for a random sentence in the test set\n",
    "i = random.randint(0, len(test_labels) - 1)\n",
    "\n",
    "print('Sentence:', test_text[i])\n",
    "print('Emotion:', index_to_class[test_labels[i]])\n",
    "\n",
    "p = model.predict(np.expand_dims(test_seq[i], axis=0))[0]\n",
    "pred_class = index_to_class[np.argmax(p).astype('uint8')]\n",
    "\n",
    "print('Predicted Emotion:', pred_class)\n",
    "\n",
    "#Output a confusion matrix for the model performance on the test set\n",
    "preds = np.argmax(model.predict(test_seq), axis=-1)\n",
    "show_confusion_matrix(test_labels, preds, list(classes))\n",
    "\n",
    "#Output Precision, Recall and F1-Scores on the model performance for each class\n",
    "print(classification_report(test_labels, preds))\n",
    "\n",
    "#Save the Model\n",
    "from datetime import datetime\n",
    "model.save(\"C:/Users/valsa/OneDrive - The University of the West Indies, St. Augustine/Final Year/ECNG 3020/Python Scripts/Alternative Model/SA_Model_Alt_{}\".format(datetime.now().strftime(\"%d%m%Y_%H_%M_%S\")))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
